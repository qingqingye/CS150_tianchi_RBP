{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# unzip all datafile in <PROJECT_ROOT>/data_format1/*\n",
    "# dataset is huge. So this may take some time ...\n",
    "project_root = \".\" # this di\n",
    "data_folder =  \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(os.path.join(project_root, data_folder ,\"test_format1.csv\"))\n",
    "data_usr = pd.read_csv(os.path.join(project_root, data_folder ,\"user_info_AGNormal_dv.csv\"))\n",
    "agg_merchant = pd.read_csv(os.path.join(project_root, data_folder ,\"agg_merchant.csv\"))\n",
    "agg_user = pd.read_csv(os.path.join(project_root, data_folder ,\"agg_user.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(os.path.join(project_root, data_folder ,\"train_format1.csv\"))\n",
    "merchant_profile = pd.read_csv(os.path.join(project_root, data_folder ,\"merchant_profile_dc_dv.csv\"))\n",
    "data_train_embedding = pd.merge(data_train, merchant_profile, how='left', on=['merchant_id'])\n",
    "data_train_embedding = pd.merge(data_train_embedding, data_usr, how='left', on=['user_id'])\n",
    "data_train_embedding = pd.merge(data_train_embedding, agg_merchant, how='left', on=['merchant_id'])\n",
    "data_train_embedding = pd.merge(data_train_embedding, agg_user, how='left', on=['user_id'])\n",
    "data_train_embedding.drop(['merchant_id','user_id','Unnamed: 0_x','Unnamed: 0_y'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(os.path.join(project_root, data_folder ,\"test_format1.csv\"))\n",
    "data_test_embedding = pd.merge(data_test, merchant_profile, how='left', on=['merchant_id'])\n",
    "data_test_embedding = pd.merge(data_test_embedding, data_usr, how='left', on=['user_id'])\n",
    "data_test_embedding = pd.merge(data_test_embedding, agg_merchant, how='left', on=['merchant_id'])\n",
    "data_test_embedding = pd.merge(data_test_embedding, agg_user, how='left', on=['user_id'])\n",
    "data_test_embedding.drop(['merchant_id','user_id','Unnamed: 0_x','Unnamed: 0_y'],axis=1,inplace=True)\n",
    "data_test_embedding.drop(['prob'],axis=1,inplace=True)\n",
    "data_test_embedding.fillna(0,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_embedding.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(data_train_embedding).T\n",
    "print(train)\n",
    "test = np.array(data_test_embedding)\n",
    "train_y = train[:][0]\n",
    "train_X = train[:][1:].T\n",
    "train_X.shape\n",
    "#split data into x y\n",
    "# dtrain = xgb.DMatrix(train)\n",
    "# dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "kf = KFold(train_X.shape[0], n_folds=10, shuffle=True)\n",
    "clf = xgb.XGBClassifier(seed=7,silent=False,n_jobs =-1)\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# clf=GradientBoostingRegressor(\n",
    "#   loss='ls', learning_rate=0.1, n_estimators=100, subsample=1, min_samples_split=2, min_samples_leaf=1, \n",
    "#     max_depth=7, init=None, random_state=None, max_features=None, alpha=0.9, verbose=1, max_leaf_nodes=None, \n",
    "#     warm_start=False,\n",
    "# )\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth=5, random_state=0,n_jobs =-1)\n",
    "\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC(kernel='linear', C=1)\n",
    "\n",
    "# kf = tqdm(kf, ascii = True, ncols = 88)\n",
    "# tqdm is a progress bar function.\n",
    "# kf.set_description(\"acc %0.03f %%\"%(0*100))\n",
    "for epoch , (train_index, test_index) in enumerate(kf):\n",
    "    X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "    y_train, y_test = train_y[train_index], train_y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions=clf.predict_proba(X_test)#每一类的概率\n",
    "    false_positive_rate, recall, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "    roc_auc=auc(false_positive_rate,recall)\n",
    "#     kf.set_description(\"acc %0.03f %%\"%(roc_auc*100))\n",
    "    print(\"=> finished epoch %d, val acc %0.03f %%\"%(epoch,roc_auc*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_X,train_y)\n",
    "predictions=clf.predict_proba(train_X)#每一类的概率\n",
    "false_positive_rate, recall, thresholds = roc_curve(train_y, predictions[:, 1])\n",
    "roc_auc=auc(false_positive_rate,recall)\n",
    "print(\"=> after all, train acc %0.03f %%\"%(roc_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (clf.predict_proba(test).T[1].T)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['prob'] = DataFrame(pred)\n",
    "data_test.set_index(['user_id', 'merchant_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.to_csv(os.path.join(project_root, 'submit', 'TeYeT_ass' ,\"xgb_macrTT_mdcTT_uacrTT_udv_mdv_maggTT_uaggTT_mr.csv\"))\n",
    "# uacr - merchant action count rate monthly(all) \n",
    "# macr - merchant action count rate monthly(all) \n",
    "# mr - merchant repeat rate\n",
    "# mdc - merchant day count\n",
    "# TT - total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
